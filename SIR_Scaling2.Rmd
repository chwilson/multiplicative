---
title: "Insights from scale transition into compartmental epidemiological models"
author: "Chris H. Wilson"
date: "4/4/2020"
output: 
  word_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr); library(lubridate); library(cowplot);
library(arm); library(maps)
library(dplyr); library(readr)


knitr::opts_knit$set(eval.after = 'fig.cap')
```
```{r putting map data together,results = 'hide', message = F, echo = F, warning = F}
urlfile="https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"
UScounty<-read_csv(url(urlfile))
UScounty$Date <- ymd(UScounty$date)
UScounty$jday <- julian(UScounty$Date)-min(julian(UScounty$Date))
UScounty$County <- as.factor(UScounty$county)
UScounty$State <- as.factor(UScounty$state)

# max(UScounty$Date) which date is most recent in data

county_ERS <- read_csv("ERS_county_data.csv")
cols_select <- c("POP_ESTIMATE_2018","fips","State","Area_Name","Rural-urban_Continuum Code_2013")
cERS <- county_ERS[,cols_select]
colnames(cERS) <- c("population","fips","State","County","Density_Code")
super <- merge(UScounty,cERS,by="fips")

super$County.y <- as.factor(super$County.y)
super$State.y <- as.factor(super$State.y)

super[which(super$County.x=="New York City"),"population"] <-  8398748 # from Wikipedia, 03/29/20
super[which(super$County.x=="Kansas City"),"population"] <- 491918 # ditto 

```


# Background 

The world is currently in the grip of a pandemic caused by the novel coronavirus SARS-CoV2. At last count, the official tally worldwide is north of 1 million confirmed cases and ~53K deaths (https://experience.arcgis.com/experience/96dd742462124fa0b38ddedb9b25e429). A great deal of attention has focused on a variety of efforts to forecast the progression of the disease, often relying on epidemiological theory (e.g.), statistical curve fitting (e.g.), or in the best case scenario, principled reconciliation of data and theory (e.g.). The fundamental theory underlying our understanding of infectious disease dynamics is encapsulated in the classical SIR equations, which I reviewed here for easy reference (https://rpubs.com/chwilson101/587211). Although the numerous assumptions of the SIR class of models are widely acknowledged, certain implications appear to be less widely appreciated. In this note, I draw attention to the fact that mean-field assumptions will fail to hold, with disastrous consequences for estimating the parameters of SIR-type equations from aggregate data. Another implication is that pandemic progression is radically *non-ergodic*. Practically speaking, this implies that local authorities should not rely on aggregate or spatially-averaged statistics to guide decision-making. 

# Setup 

To recap, the SIR equations, as I derived in (https://rpubs.com/chwilson101/587211), are:

$$\tag {1} \frac {dS}{dt} = - R_0 \nu I \frac{S}{N} $$
$$\tag {2} \frac {dI}{dt} = R_0 \nu I \frac{S}{N} - \nu I $$
$$\tag {3} \frac {dR}{dt} = \nu I $$

These equations assume a well-mixed population (the mass-action princple). It is reasonable to question this assumption at large scales. For instance, a casual glance at a map of the US based on the newly released county level data from the NYT shows striking spatial heterogeneity (Fig.1). This heterogeneity is apparent at both national and state levels. 


```{r National Map of Covid Cases, echo = F, message = F, warning = F, fig.height = 5, fig.width = 8}

### NYT Covid Data 

######### Trying with urbanmapr 
#devtools::install_github("UrbanInstitute/urbnmapr")
library(urbnmapr)
#library(ggplot2)
#library(dplyr)
# map subtitle 
subtitle_s <- paste("Date:",paste(max(UScounty$Date)))

# Obtain county polygon data
states_sf <- get_urbn_map(map = "states", sf = TRUE)
counties_sf <- get_urbn_map(map = "counties", sf = TRUE)
colnames(counties_sf)[1] <- "fips"

# Recall: super <- merge(UScounty,cERS,by="fips")
counties_sf2 <- left_join(counties_sf,super %>% filter(Date ==max(UScounty$Date)),by="fips")

#counties_sf$value = runif(length(counties_sf$county_fips), min=-1.0, max=1.0)

# Plot county level data 
  ggplot() +
    # Plot county data and fill with value
   geom_sf(data=counties_sf2, mapping = aes(fill = 10^4*(cases/population)), color =     NA) +
        # Overlay State Outlines

     geom_sf(data = states_sf, fill = NA , color = "black", size = 0.25) +
    # Remove grid lines from plot
    coord_sf(datum = NA) +   
    labs(fill = "Random Data") + 
    scale_fill_viridis_c(option = "viridis", direction = -1,name="Covid-19 Cases   (per 10K)",na.value = "#CCCCFF") +
labs(title="Covid-19 in the United States", subtitle = 
                 subtitle_s) +

    theme_bw() + 
    theme(
    # Hide panel borders and remove grid lines
    panel.border = element_blank())

#cap <- "$\\textit{Figure 1: Map of confirmed Covid-19 cases in the US broken down by county. Data from the New York Time: https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv}$"
```

*Figure 1: Map of confirmed Covid-19 cases in the US broken down by county. Data from the New York Time: https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv*

However, it might be countered that we can still usefully apply the theory if only we are willing to interpret the parameters in a "mean field" fashion. Practically speaking, this is exactly what is assumed any time such a model is fit to aggregated data. We hope that the temporal trend (time series) and spatial variations hang together, amounting to an assumption of some form of ergodicity. 

# Applying the scale transition 

The scale transition theory from ecology (notably developed by Chesson XXXX,and XXXX) can provide theoretical insight into the breakdown of this assumption and its consequences. We apply it as follows: let us consider each disaggregated unit (in this case, a 'county') as our local 'patch model'. We index the location in space with 'x', and rewrite our equations for any given patch as: 

$$\tag {4} \frac {dS_x}{dt} = - R_{0_x} \nu_x I_x \frac{S_x}{N_x} $$
$$\tag {5} \frac {dI_x}{dt} = R_{0_x} \nu_x I_x \frac{S_x}{N_x} - \nu_x I_x $$
$$\tag {6} \frac {dR_x}{dt} = \nu_x I_x $$

For simplicity, I will simply linearize equation 5 under assumption that our attention is on early phase ($S \approx N$): 

$$\tag {7} \frac {dI_x}{dt} = \nu_x (R_{0_x} - 1) I_x $$
Following Chesson XXXX, if we assume there are a large number of spatial locations, we can estimate the area-wide dynamics by taking the expectation over space: 

$$\tag {8} \mathop{\mathbb{E_x}}[\frac {dI_x}{dt}] = \mathop{\mathbb{E_x}}[\nu_x (R_{0_x} - 1) I_x]$$
That is to say, for a sufficiently short interval of time, the RHS of equation 8 will represent the change in the number of infecteds in the population. In most applications of the scale transition, we are particularly concerned by the combination of non-linear equations and heterogeneity. In this case, our dynamics are first order, and at first glance this would suggest that our model should scale up just fine, even with lots of heterogeneity. 

Wrung. 

I will illustrate the breakdown of this hope with an even simpler model. Let us suppose for now that there is not meaningful variation in $\nu$, and so our county units vary principally in $R_0$ (and I collapse $R_0$-1 to $\psi$ for simplicity) and the current number of infecteds $I$. Given their representation as random variables in the patch model, the aggregate model is simply the product of the random variables: 

$$\tag {9} \overline{\frac {dI_x}{dt}} = \overline{\nu \psi_x I_x} = \nu \overline{\psi}\overline{I} + cov(\psi,I)$$
In short, equation 9 simply says we have to correct the mean-field model ($\nu \overline{\psi}\overline{I}$) with the covariance in $R_0$ and $I$. So far so good. If we want to rescue good parameter estimates for $R_0$ from aggregate time series data we just need to know the relevant covariance. 

# Insights from the scale transition 

But wait! Look again at Fig. 1. It turns out the distribution over $I$ is **extremely** fat-tailed. Even after normalization by population density within a county (itself a fat-tailed quantity), it remains fat-tailed and fairly well described by a Pareto distribution with low $\alpha$ exponent. Rather than national-level, I show this in Fig. 2 specifically for the case of New York (Fig 2a has all county trajectories, 2b has a histogram). 

```{r NY case demo, echo = F, message = F, warning = F,fig.height = 3, fig.width = 10}

NYdata <- super %>% filter(State.x == "New York")
NYdata <- NYdata %>% mutate(NormRate = 10^4*(cases/population))

p1 <- ggplot(NYdata, aes(x=Date,y=10^4*(cases/population),group=County.x)) + geom_point() + geom_line() + ylab("") + xlab("") + theme_bw(base_size=14) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("Covid-19 Cases per 10K")

p2 <- ggplot(NYdata %>% filter(Date == max(super$Date),NormRate>2), aes(x=NormRate)) + geom_histogram(bins=100) + theme_bw(base_size=14) +
  xlab("") + ylab("") + ggtitle("Covid-19 Cases per 10K")

pareto_data <- super %>% filter(State.x == "New York") %>% group_by(Date) %>%  filter(10^4*(cases/population)>2) %>% summarize(alpha_hat = n()/sum(log(10^4*(cases/population))), se_alpha = alpha_hat/sqrt(n()), empMean = mean(10^4*(cases/population)), trueMean = alpha_hat/(alpha_hat-1), ratio_empTrue = trueMean/empMean)

p3 <- ggplot(pareto_data,aes(x=Date)) + geom_point(aes(y=alpha_hat)) + geom_segment(aes(xend = Date,y=alpha_hat-(2*se_alpha),yend = alpha_hat + (2*se_alpha)),linetype="dashed") + 
  theme_bw(base_size=14) +
  geom_hline(aes(yintercept=0),color="black") + 
  geom_hline(aes(yintercept=1),color="red") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  xlab("") + ylab("") + ggtitle("Pareto alpha exponent")

#+ ggtitle("Maximum likelihood estimate of Pareto exponent", subtitle = "+/- 2 SE")

print(plot_grid(p1,p2,p3,nrow=1,labels="auto",align = 'v'))
#?plot_grid

#cap_string <- paste("Figure 2: a) time series of confirmed Covid-19 cases from every county in New York State, b) historgram of the distribution of cases on",paste(max(UScounty$Date)),"c) Result of fitting distribution of Covid-19 cases on each date to a Pareto distribution via simple maximum likelihood. Graph shows maximum likelihood estimate +/- 2 SEs. Red line shows alpha = 1, below which the first moment goes to infinity (is undefined)")


#cap <- cap_string


```

*`r paste("Figure 2: a) time series of confirmed Covid-19 cases from every county in New York State, b) historgram of the distribution of cases on",paste(max(UScounty$Date)),"c) Result of fitting distribution of Covid-19 cases on each date to a Pareto distribution via simple maximum likelihood. Graph shows maximum likelihood estimate +/- 2 SEs. Red line shows alpha = 1, below which the first moment goes to infinity (is undefined)")`*

On `r max(UScounty$Date)`, the Pareto exponent among New York counties, estimated by maximum likelihood is `r round(tail(pareto_data$alpha_hat,1),2)`, and has been declining since `r head(pareto_data$Date,1)`.

Fat-tailed distributions bring some important caveats to the table. First, for the standard Pareto distribution where the $\alpha$ goes below 2, the variance becomes infinite! Practically speaking, this means it is undefined. Thus, any covariance term (such as the correction in 9) is indeterminate. When the $\alpha$ parameter goes below 1, even the mean (first moment) no longer exists, thus rendering the rest of the terms in equation 9 problematic. 

Unfortunately, most states are showing alpha < 2, and several alpha < 1. When we, for example, fit an exponential model iteratively to each county in New York and take the mean of the estimated growth parameters (reflecting spatial variations in $R_0$), it differs systematically from the estimate based on all counties summed together, just as our analysis suggests (Figure 3). In fact, we should expect a fairly high positive covariance/correlation between $R_0$ and $I$, given the dynamics at play, and thus the aggregate estimate will be systematically higher than the mean of the disaggregated estimates. 


```{r NY scaling discrepancy, echo = F, warning = F, message = F}

NYdataSUM <- NYdata %>% filter(cases>0, county != "unknown",is.na(population)==F, is.na(cases)==F) %>% group_by(jday) %>% summarize(cases = sum(cases),pop = sum(population))
# max(NYdataSUM$pop,na.rm=T)
# str(NYdataSUM)

 # Apparent growth rate from aggregate data: 
state_gr <- coef(lm(log(10^4*(cases/max(NYdataSUM$pop)))~jday,NYdataSUM))[2]

# By County 

NYdata2 <- NYdata %>% filter(cases>0,is.na(population)==F, is.na(cases)==F, county != "unknown")


N <- length(unique(NYdata$county))
names <- unique(NYdata$county)
county_gr <- rep(0,N-1)
#str(NYdata)
for(i in 1:(N-1)){
#print(i)
#  print(NYdata %>% filter(county == names[i]))
 county_gr[i] <- coef(lm(log(10^4*(cases/population))~jday,NYdata2 %>% filter(county == names[i])))[2]
}

# mean(county_gr,na.rm=T) # 0.22 

ineq <- data.frame(x=county_gr) 
p1 <- ggplot(ineq,aes(x=x)) + geom_histogram(bins=30) + 
  geom_vline(aes(xintercept = mean(county_gr,na.rm=T))) +
  geom_vline(aes(xintercept = state_gr),color="red") + 
  ggtitle("Distribution of exponential growth rates by county")


print(p1)
# This value deviates substantially from that estimated from the statewide data, just as 
# scale tranistion theory suggests it should. IOW, our estimates of R_0 do not behave in a way
# that we would like to see! 

```

*Figure 3: Distribution of exponential growth rates fitted to each county in New York separately. The black line shows the mean of these growth rates (the mean-field interpretation of SIR), whereas the red line shows the actually estimated growth rate from the state-level data fitted as an aggregate. This clearly demonstrates the breakdown of the mean-field assumption, exactly as predicted by the theoretical analysis here.* 

What's more, increasing fat-tailedness within a state is exponentially correlated with the state-level aggregated prevalence of Covid-19. This fine-grained spatial pattern is absolutely critical to accurately understanding and forecasting Covid-19 (Figure 4). 

```{r fitting Pareto distro within states, echo = F, message = F}
table_1 <- super %>% filter(Date == max(UScounty$Date)) %>% group_by(State.x) %>% filter(10^4*(cases/population)>1) %>% summarize(alpha_hat = n()/sum(log(10^4*(cases/population))), se_alpha = alpha_hat/sqrt(n()), empMean = mean(10^4*(cases/population)), trueMean = alpha_hat/(alpha_hat-1), ratio_empTrue = trueMean/empMean)

p1 <- ggplot(table_1, aes(x=alpha_hat,y=empMean)) + geom_point() + ylab("State-level Covid-19 (cases/10K)") + 
  xlab(paste("Pareto exponent for distribution of cases on",max(UScounty$Date))) + geom_vline(aes(xintercept=1),color="red")

print(p1)


## YUGE range of variation within States. The hardest hit states have the lowest exponents. A couple 
# certainly < 1, and several probably < 1. Which means that no moments exist at all! This destroys 
# the aggregation properties entirely. 
```

*Figure 4: As Pareto exponent declines, the aggregate state situation gets exponentially worse. The spatial dynamics of Covid are such that individual counties/cities are driving the entire story.* 


# Conclusions 

Formally, the equations (4,5,6) cannot necessarily be solved given the closure problem (minimally, we would need equations desribing how all the covariances evolve, and to demonstrate that the whole system obeyed conservation principles, etc.) However, our analysis of equation 9, in tandem with the data shown in figures 1 and 2, is sufficient to show that estimates of $R_0$ from aggregated data are systematically biased. Unfortunately, since the moments of the relevant distributions do not exist, we cannot rigorously account for this bias. Attempts to empirically estimate the covariance in equation 9 will require substantially more data than otherwise, and the empirical mean of $I$ will fail to represent the "true" mean in equation 9 when the distribution is sufficiently fat-tailed. 

Our best chance at understanding and forecasting Covid-19 is to develop models at as granular a level as possible, and then rigorously and explicitly account for spatial interconnections and processes. This is a lot of work, and may be logistically challenging. Accordingly, for strategic planning purposes, SIR-type models should be used to educate the intuition about what is possible, but decisions should be made with a rather strong precautionary approach. 


